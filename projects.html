<!-- Credits to OmahPSD. Thanks a lot! -->

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
	
    <title>Vaidehi - My Projects</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Add custom CSS here -->
	
    <link href="css/style.css" rel="stylesheet">
    <link href="css/ekko-lightbox.css" rel="stylesheet">
    <link href="css/flexslider.css" rel="stylesheet">
    <link href="css/animate.min.css" rel="stylesheet">
    <link href="font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="css/bootstrap-theme.min.css" rel="stylesheet">
		<!--[if lt IE 9]>
		<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
		<![endif]-->
  </head>

  <body>
  <div id="boxWrapp">
    <div class="main-nav clearfix">
	  <!-- navbar -->
	<nav class="navbar navbar-inverse" role="navigation">
        <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#NavCol">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand bg-primary" href="#about">VAIDEHI</a>
        </div>
        
        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="NavCol">
         <ul class="nav navbar-nav navbar-right">
           
            <li class="current"><a href="#about" class="linear">Home</a></li>
            <!-- <li><a href="#ProjectList" class="linear">Project List</a></li> -->
            <li><a href="#WorkExp" class="linear">Work Experience</a></li>
            <li><a href="#Projects" class="linear">Projects</a></li>
          </ul>
        
         
        </div><!-- /.navbar-collapse -->
        </div><!-- /.container-fluid -->
    </nav>
	  
	</div>
    <!-- Full Page Image Header Area -->
    <div id="about" class="header">
		<div class="maskHeader"></div>
		<div class="main-caption">
				<!-- slider -->
		<div id="flex-head" class="flexslider">
			<ul class="slides">
				<li>
					<h1>Welcome to the Projects page</h1>
					<h2>Read more for details about my projects</h2>
					<a href="#Projects" class="btn btnAbout btn-clear border-color color-primary btn-lg linear">PROJECTS</a>
				</li>
                <!-- <li>
                    <h1>Projects at a Glance</h1>
                    <h2>Click below to see a categorized list of the projects</h2>
                    <a href="#ProjectList" class="btn btnAbout btn-clear border-color color-primary btn-lg linear">PROJECT LIST</a>
                </li> -->
				<li>
					<h1>This page also contains details of my Work Experience</h1>	
					<h2>The description of my internship projects are also provided below</h2>
					<a href="#WorkExp" class="btn btnAbout btn-clear border-color color-primary btn-lg linear">WORK EXPERIENCE</a>
				</li>
			</ul>
		</div> 
	    <!-- end slider --> 
	</div><!--  end main caption -->
			
    </div>
	<!-- end header -->
    <!-- /Full Page Image Header Area -->


    <!-- Internships -->
    <div id="WorkExp" class="page clearfix">
        <div class="container">
			<div class="row">
        		<div class="col-md-10  col-md-offset-1">
		    		<div class="build title-page">
						<h2 class="text-center">WORK EXPERIENCE</h2>	
							<div class="line-title bg-primary"></div>
					</div>
		 		</div><!-- end col -->
			</div><!-- end row -->
    	</div>
    </div><!--end container-->

    <!-- CARIS -->
    <div id="caris" class="page clearfix">
		<div class="container ptb">        
	      	<div class="row">
			<div class="col-md-10  col-md-offset-1">
		    		<div class="build title-page">
						<h2 class="text-center">PAL Lab- GRASP, University of Pennsylvania</h2>	
							<div class="line-title bg-primary"></div>
					</div>
			 	</div><!-- end col -->
			</div><!-- end row -->

	        <div class="row">
				<div class="col-md-4">
		          <h5><b>THE RESEARCH</b></h5>
		          <p class="desc">I am a Research Assistant at <a href="">Perception, Action, and Learning (PAL) Lab</a> at GRASP, 
                University of Pennsylvania. I am being mentored by <a href="">Dr. Dinesh Jayaraman</a>, lead PAL Lab and 
                  <a href="">Jason Ma</a>, doctoral student under Dr. Dinesh. We am working on making the robot perform household tasks in 
                unstructured environment based on very little data using Reinforcement Learning. 
                My research involves me preparing different architectures to train policies which can perform 
                tasks given by language commands. 
                The policy is trained on data collected on Franka Panda robotic arm and is also tested on the same hardware.</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-4">
		          <h5><b>SINGLE-ARM REACH PREDICTION</b></h5>
		          <p class="desc">The main project I worked on was related to prediction of single arm motion by humans 
                to create smooth human robot interactions, and was mentored by Justing Hart and Elizabeth Croft. 
                It involved studying and analyzing the performance of multiple Hand and Model trackers and their 
                inclusion in our pipeline. I also developed multiple interfaces to be used in the experimental setup 
                for the final Human subject experiments.</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-4">
		          <h5><b>MERGING POINT CLOUDS</b></h5>
		          <p class="desc"> The project aims at merging unaligned point clouds from multiple kinects to gain additional information, and was mentored by Justin Hart, Post Doc, CARIS Lab. It involved a literature survey on existing work for Camera Calibration and Distortion reduction in cameras. A transformation between the Kinects was computed using the extracted camera parameters, which was further used to align the Point Clouds. Averaging using Rodriguez representation along with Bundle Adjustment was performed to improve the results.</p>
	        	</div><!--/col-md-4-->
	      	</div><!--/row-->

		   	<br><br>

	      	<div class="row">
			  	<div class="col-md-6">
		      		<center><a href="" class="btn btn-clear btn-lg border-color linear hire">PRELIMINARY RESULTS</a></center>	
				</div>
	          	<div class="col-md-6">
		      		<center><a href=# class="btn btn-clear btn-lg border-color linear hire">CODE CONFIDENTIAL (FOR NOW)</a></center>
				</div>
	      	</div><!--/row-->
	      	<br>

	    </div>
    </div>

    <!-- XRCI -->
    <div id="xrci" class="page clearfix">
		<div class="container ptb">        
	      	<div class="row">
			<div class="col-md-10  col-md-offset-1">
		    		<div class="build title-page">
						<h2 class="text-center">Addverb Technologies, India</h2>	
							<div class="line-title bg-primary"></div>
					</div>
			 	</div><!-- end col -->
			</div><!-- end row -->

	        <div class="row">
				<div class="col-md-4">
		          <h5><b>THE WORK</b></h5>
		          <p class="desc"> I was a Mobile Robotics Software Engineer at Addverb Technologies, India.
                 
                I interned at Xerox Research Centre India, Bangalore during winters '15 (i.e. December '15). 
                I was mentored by Om Deshmukh, Senior Researcher (Area Manager, Multimedia Analytics), XRCI and 
                Sumit Negi, Principal Researcher, XRCI , for developing and evaluating algorithms for 
                Multi View Clustering using Non Negative Matrix factorization. 
                The work involved proposing and evaluating various algorithms for the task. 
                Further details upon completion of the work. 
                The work has been accepted as an <b>Oral</b> presentation at the <b>International Conference on 
                Pattern Recognition '16</b>.</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-5">
		          <h5><b>THE PROJECT</b></h5>
		          <p class="desc">The project deals with the problem of clustering data using information present in Multiple Views. We propose several extensions to tackle the Partial Multi View problem which involve data with missing views i.e. not all instances have all views. There has been relatively less work in the field even though it is quite a realistic assumption when we consider real world data. Our proposed models have simple update rules which result in ease of computation. We compare the performance of our approaches with previous models on diverse datasets (including image and textual datasets) and find that our model outperforms them.</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-3">
		          <h5><b>THE RESULTS</b></h5>
		          <p class="desc"> We compare the performance of our approaches with previous models in the field; our model outperforms the state of the art methods. We use both Image and Textual data to ensure diversity during the experiments. As our approach includes graph regularization, we also study the effect of different kernels on the performance. Additional experiments have been described in the paper.</p>
	        	</div><!--/col-md-4-->
	      	</div><!--/row-->

		   	<br><br>

		   	<!-- External Links -->
	      	<div class="row">
			  	<div class="col-md-4">
		      		<center><a href="resources/gpmvc_presentation.pdf" class="btn btn-clear btn-lg border-color linear hire">PRESENTATION</a></center>	
				</div>
			  	<div class="col-md-4">
		      		<center><a href="projects.html#gpmvc" class="btn btn-clear btn-lg border-color linear hire">PROJECT DETAILS</a></center>	
				</div>
	          	<div class="col-md-4">
		      		<center><a href="https://github.com/nishantrai18/MultiViewNMF" class="btn btn-clear btn-lg border-color linear hire">CODE REPOSITORY</a></center>
				</div>
	          	<!--
	          	<div class="col-md-4">
		      		<center><a href="resume/m_resume.pdf" class="btn btn-clear btn-lg border-color linear hire">RESUME</a></center>	
				</div>         
	      		-->
	      	</div><!--/row-->
	      	<br>
        
        <br>

	    </div>
    </div>

    <!-- I.N.R.I.A. Rocquencourt -->
    <div id="inria" class="page clearfix">
		<div class="container ptb">        
	      	<div class="row">
			<div class="col-md-10  col-md-offset-1">
		    		<div class="build title-page">
						<h2 class="text-center">I.N.R.I.A. Rocquencourt</h2>	
							<div class="line-title bg-primary"></div>
					</div>
			 	</div><!-- end col -->
			</div><!-- end row -->

	        <div class="row">
				<div class="col-md-4">
		          <h5><b>THE INTERNSHIP</b></h5>
		          <p class="desc">I interned at I.N.R.I.A., Rocquencourt, France during Summers '15 (i.e. May '15 - July '15). I was working simultaneously on two projects during my stay there. I was mentored by Mentored by Laurent Viennot, Senior Researcher, INRIA and Adrian Kosowski, Researcher, INRIA , for finding routes substantially different from the shortest path based on different criteria. The work involved proposing and evaluating various algorithms for the task. I was also working with Adrian Kosowski, Researcher, INRIA for finding good local features which are suitable predictors for global features. Further details for the alternate path project will be available upon completion of the work.</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-4">
		          <h5><b>ALTERNATE PATHS</b></h5>
		          <p class="desc">The aim of the project was finding routes substantially different from the shortest path based on different criteria. I implemented various shortest path algorithms and compared their efficiency on real world road networks. It also involved proposing algorithms to compute paths according to another feasible (also proposed) definition. FInally, we created measures to compare different algorithms developed efficient algorithms for the involved computations. Exact plots of the computed alternate paths on various road networks and scores/results will be available soon.</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-4">
		          <h5><b>SOCIAL NETWORK ANALYSIS</b></h5>
		          <p class="desc">The project aims at finding good local features which are suitable predictors for global features. I implemented and studied randomized rumor spreading, the relation between size and steps for spread of the rumor. I further explored different local features in graphs based on walks, subgraph densities, centrality measures and their relation with other global properties along with arguments to explain the obtained results. I also collaborated with the ERC (Funded by the European Research Council) World Seastems project during the course of the internship.	</p>
	        	</div><!--/col-md-4-->
	      	</div><!--/row-->

		   	<br><br>

	      	<div class="row">
			  	<div class="col-md-6">
		      		<center><a href=# class="btn btn-clear btn-lg border-color linear hire">MORE SOON</a></center>	
				</div>
	          	<div class="col-md-6">
		      		<center><a href=# class="btn btn-clear btn-lg border-color linear hire">CONFIDENTIAL (FOR NOW)</a></center>
				</div>
	          	<!--
	          	<div class="col-md-4">
		      		<center><a href="resume/m_resume.pdf" class="btn btn-clear btn-lg border-color linear hire">RESUME</a></center>	
				</div>         
	      		-->
	      	</div><!--/row-->
			<br>
	    </div>
    </div>

    <!-- Projects -->
    <div id="Projects" class="page clearfix">
        <div class="container">
			<div class="row">
        		<div class="col-md-10  col-md-offset-1">
		    		<div class="build title-page">
						<h2 class="text-center">PROJECTS</h2>	
							<div class="line-title bg-primary"></div>
					</div>
		 		</div><!-- end col -->
			</div><!-- end row -->
    	</div>
    </div><!--end container-->

    <!-- AdaScan -->
    <div id="adascan" class="page clearfix">
		<div class="container ptb">        
	      	<div class="row">
			<div class="col-md-12  col-md-offset-0">
		    		<div class="build title-page">
						<h2 class="text-center">AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for Human Action Recognition in Videos</h2>	
							<div class="line-title bg-primary"></div>
					</div>
			 	</div><!-- end col -->
			</div><!-- end row -->

        <div class="container">
           <div class="row panel-default">
            <div class="col-md-10  col-md-offset-1">
              <div class="panel-body">

                  <h4>
                    <strong>Abstract:</strong>
                  </h4>
                  <p class="desc"> We propose a novel method for temporally pooling frames in a video for the task of human action recognition. The method is motivated by the observation that there are only a small number of frames which, together, contain sufficient information to discriminate an action class present in a video, from the rest. The proposed method learns to pool such discriminative and informative frames, while discarding a majority of the non-informative frames in a single temporal scan of the video. Our algorithm does so by continuously predicting the discriminative importance of each video frame and subsequently pooling them in a deep learning framework. We show the effectiveness of our proposed pooling method on standard benchmarks where it consistently improves on baseline pooling methods, with both RGB and optical flow based Convolutional networks. Further, in combination with complementary video representations, we show results that are competitive with respect to the state-of-the-art results on two challenging and publicly available benchmark datasets.
                  </p>
                  <br>

                    <h4>
                    	<strong>Results:</strong>
                    </h4>

                    <br>

				    <img src="img/details/ada_results.jpg" alt="Qualitative Results">              
				    <br><br>

				    <img src="img/details/ada_table.jpg" alt="Quantitative Results">
				    <br><br>

                    <h4>
                    	<strong>Relevant Links:</strong>
                    </h4>

                    <br><br>

				   	<!-- External Links -->
			      	<div class="row">
					  	<div class="col-md-6">
				      		<center><a href="resources/adascan.pdf" class="btn btn-clear btn-lg border-color linear hire">PAPER</a></center>
						</div>
			          	<div class="col-md-6">
				      		<center><a href=# class="btn btn-clear btn-lg border-color linear hire">CODE REPOSITORY (SOON)</a></center>
						</div>
			      	</div><!--/row-->
			      	<br>

              </div>
            </div>
          </div>
        </div>

	    </div>
    </div>

    <!-- Visual Story Telling -->
    <div id="story" class="page clearfix">
        <div class="container ptb">        
            <div class="row">
            <div class="col-md-10  col-md-offset-1">
                    <div class="build title-page">
                        <h2 class="text-center">Visual Story Telling</h2> 
                            <div class="line-title bg-primary"></div>
                    </div>
                </div><!-- end col -->
            </div><!-- end row -->

            <div class="row">
                <div class="col-md-4">
                  <h5><b>THE PROJECT</b></h5>
                  <p class="desc">This was a course project in the course CS698A: Recent Advances in Computer Vision, under Prof. Gaurav Sharma. Visual Story telling is relatively new task with hardly any prior work. The task involves mapping sequential images to sequential, human like, narrative descriptive sentences or ’stories’. Simply put, it involves understanding a sequence of images and trying to explain its contents in a story like manner. The problem was introduced recently along with a newly constructed dataset (released by MSR).</p>
                </div><!--/col-md-4-->
                <div class="col-md-5">
                  <h5><b>PROJECT DESCRIPTION</b></h5>
                  <p class="desc">The project deals with the task of visual story telling i.e. constructing narratives given sequential images. In our approach, we encode the image sequence by passing it through a GRU. This is used as the initial hidden state of the story decoder network, which is also modelled as a GRU. Finally, beam search is used to produce the story for each sequence. Specific heuristics are also discussed to further improve performance. We work with a newly constructed dataset released by MSR which consists of around 80k images in 20k sequences. We use METEOR and BLEU scores as evaluation metrics for this task. The code repository is hosted at GitHub.</p>
                </div><!--/col-md-4-->
                <div class="col-md-3">
                  <h5><b>THE RESULTS</b></h5>
                  <p class="desc"> Although the metrics used (METEOR and BLEU) correlate well with human judgements, their ineffectiveness in such a task is notable. They often fail to assign accurate scores to the generated stories, mainly due to the numerous 'correct' stroies for each image sequence. Other qualitative results are provided in the report and presentation.</p>
                </div><!--/col-md-4-->
            </div><!--/row-->

            <div class="row">
            <br><br>
            <center><img src="img/details/story_example.jpg" alt="Results" style="width: 75%; height: 75%"></center>
            <br><br><br>
            </div>

            <div class="row">
                <div class="col-md-4">
                    <center><a href="resources/cs698_presentation.pdf" class="btn btn-clear btn-lg border-color linear hire">PRESENTATION</a></center>   
                </div><!--/col-md-4-->
                <div class="col-md-4">
                    <center><a href="resources/cs698_report.pdf" class="btn btn-clear btn-lg border-color linear hire">REPORT</a></center>
                </div><!--/col-md-4-->
                <div class="col-md-4">
                    <center><a href="#" class="btn btn-clear btn-lg border-color linear hire">CODE REPOSITORY (SOON)</a></center>   
                </div><!--/col-md-4-->         
            </div><!--/row-->

            <br>
        </div>
    </div>

    <!-- Visual Question Answering via Semantic Attention-->
    <div id="vqa" class="page clearfix">
        <div class="container ptb">        
            <div class="row">
            <div class="col-md-10  col-md-offset-1">
                    <div class="build title-page">
                        <h2 class="text-center">Visual Question Answering via Semantic Attention</h2> 
                            <div class="line-title bg-primary"></div>
                    </div>
                </div><!-- end col -->
            </div><!-- end row -->

            <div class="row">
                <div class="col-md-4">
                  <h5><b>THE PROJECT</b></h5>
                  <p class="desc">This was a course project in the course CS676A: Computer Vision and Image Processing, under Prof. Vinay Namboodiri. The project deals with the problem of Visual Question Answering. We propose several models to tackle the problem consisting of models consisting of Bag of Words, and deep networks (such as CNNs and LSTMs). We also explore the role of attention in improving the performance of the model. The dataset used is the popular VQA dataset based on MS COCO.</p>
                </div><!--/col-md-4-->
                <div class="col-md-4">
                  <h5><b>PROJECT DESCRIPTION</b></h5>
                  <p class="desc">The project deals with the task of visual question answering i.e. building a system capable of answering open ended questions on real world images. In our approach, we first compute a representation of the question by using word vectors. We encode the image by taking the activations of VGG-16. These represenations are then used to compute the answer. We study the effect of attention models on the performance of the system. More details are present in the report.</p>
                </div><!--/col-md-4-->
                <div class="col-md-4">
                  <h5><b>THE RESULTS</b></h5>
                  <p class="desc"> We use the VQA dataset based on the popular MS COCO image dataset. It currently has 360K questions on 120K images. All the questions are human-generated, and were specifically designed to stump a 'smart robot'. We find that although attention based do not provide competitive performance, they are able to get a few tough questions correct. Other qualitative results are provided in the report and presentation.</p>
                </div><!--/col-md-4-->
            </div><!--/row-->

            <div class="row">
            <br><br>
            <center><img src="img/details/vqa_model.jpg" alt="Proposed Models" style="width: 90%; height: 90%"></center>
            <br><br><br>
            </div>

            <div class="row">
                <div class="col-md-4">
                    <center><a href="resources/cs676_poster.pdf" class="btn btn-clear btn-lg border-color linear hire">POSTER</a></center>   
                </div><!--/col-md-4-->
                <div class="col-md-4">
                    <center><a href="resources/cs676_report.pdf" class="btn btn-clear btn-lg border-color linear hire">REPORT</a></center>
                </div><!--/col-md-4-->
                <div class="col-md-4">
                    <center><a href="resources/cs676_code.zip" class="btn btn-clear btn-lg border-color linear hire">CODE</a></center>   
                </div><!--/col-md-4-->         
            </div><!--/row-->

            <br>
        </div>
    </div>

    <!-- Chalearn Personality Trait Analysis -->
    <div id="chalearn" class="page clearfix">
        <div class="container ptb">        
            <div class="row">
            <div class="col-md-12  col-md-offset-0">
                    <div class="build title-page">
                        <h2 class="text-center">Bi-modal Regression for Apparent Personality Trait Recognition</h2>    
                            <div class="line-title bg-primary"></div>
                    </div>
                </div><!-- end col -->
            </div><!-- end row -->

        <div class="container">
           <div class="row panel-default">
            <div class="col-md-10  col-md-offset-1">
              <div class="panel-body">

                  <h4>
                    <strong>Abstract:</strong>
                  </h4>
                  <p class="desc"> The task of the ChaLearn Apparent Personality Analysis: First Impressions Challenge is to rate/quantify personality traits of users in short video sequences. Although the validity of personality judgments from short interactions is questionable, studies show the possibility of predicting attributed traits (First Impressions) using facial and acoustic features. The challenge introduces a newly constructed dataset which consists of manually annotated videos collected from YouTube. In this paper, we present our approach for predicting traits by combining multiple modality specific models. Our models include Deep Networks which focus on leveraging visual information in the given faces, Networks focusing on supplementary information from the background and models using acoustic features. We also discuss another approach for modeling traits as a combination of global and trait-specific variables. We explore methods for extracting fixed length descriptors of videos based on frame-level predictions. We also experiment with various methods for fusing model predictions. We observe that fusion achieves a considerable gain in accuracy over the best stand-alone model, possibly due to utilizing information from all modalities. The proposed method achieves an accuracy gain of approximately 18% above the provided challenge baseline.
                  </p>
                  <br>

                    <h4>
                        <strong>Relevant Links:</strong>
                    </h4>

                    <br><br>

                    <!-- External Links -->
                    <div class="row">
                        <div class="col-md-4">
                            <center><a href="resources/chalearn_presentation.pdf" class="btn btn-clear btn-lg border-color linear hire">PRESENTATION</a></center>
                        </div>
                        <div class="col-md-4">
                            <center><a href="resources/chalearnICPR16.pdf" class="btn btn-clear btn-lg border-color linear hire">PAPER</a></center>
                        </div>
                        <div class="col-md-4">
                            <center><a href="https://github.com/nishantrai18/miscProg/tree/master/chaLearn" class="btn btn-clear btn-lg border-color linear hire">CODE REPOSITORY</a></center>
                        </div>
                    </div><!--/row-->
                    <br>

              </div>
            </div>
          </div>
        </div>

        </div>
    </div>

    <!-- Real Time Vehicle Recognition and Automatic Number Plate Recognition -->
    <div id="vehicle" class="page clearfix">
        <div class="container ptb">        
            <div class="row">
            <div class="col-md-12  col-md-offset-0">
                    <div class="build title-page">
                        <h2 class="text-center">Real Time Vehicle Classification and License Plate Recognition</h2> 
                            <div class="line-title bg-primary"></div>
                    </div>
                </div><!-- end col -->
            </div><!-- end row -->

            <div class="row">
                <div class="col-md-4">
                  <h5><b>THE PROJECT</b></h5>
                  <p class="desc">This was a course project in the course CS771A: Machine Learning, Tools and Techniques, under Prof. Harish Karnick. The project aims at detecting and classifying relevant objects in a video stream (Surveillance Video) in real time. In case of four wheelers, detection and recognition of license plate is also desired. We discuss the major intermediate steps required for the same. In the report, we propose multiple methods and discuss the related results. We also study inter class relationships and effect of fusing classes on the performance.</p>
                </div><!--/col-md-4-->
                <div class="col-md-4">
                  <h5><b>PROJECT DESCRIPTION</b></h5>
                  <p class="desc">The project aims at detecting and classifying relevant objects in a video stream (Surveillance Video) in real time. In case of four wheelers, detection and recognition of license plate is also desired. The dataset consists surveillance videos from the campus security cameras. We perform data preprocessing and cleaning. Due to the poor dataset quality (and small size), aggressive data augmentation has been performed. The pipeline is divided into intermediate steps, which are discussed in detail in the report and presentation.</p>
                </div><!--/col-md-4-->
                <div class="col-md-4">
                  <h5><b>THE RESULTS</b></h5>
                  <p class="desc"> The dataset has been collected through crowd sourcing and consists of seven classes. There are many issues in the dataset such as numerous incorrectly marked objects, low diversity and low number of images. We experiment with varioius features and classfication algorithms, their effect on performance is discussed in the report. We also experiment with various combination of classes and find that some pair of classes tend to be more confused (Such as bicyle and person). Other qualitative results are also provided.</p>
                </div><!--/col-md-4-->
            </div><!--/row-->

            <br>

            <div class="row">
                <div class="col-md-4">
                    <center><a href="resources/cs771_presentation.pdf" class="btn btn-clear btn-lg border-color linear hire">PRESENTATION</a></center>   
                </div><!--/col-md-4-->
                <div class="col-md-4">
                    <center><a href="resources/cs771_report.pdf" class="btn btn-clear btn-lg border-color linear hire">REPORT</a></center>
                </div><!--/col-md-4-->
                <div class="col-md-4">
                    <center><a href="resources/cs771_code.zip" class="btn btn-clear btn-lg border-color linear hire">CODE</a></center>
                </div><!--/col-md-4-->
            </div><!--/row-->

            <br>
        </div>
    </div>

    <!-- Word Embeddings Using Multiple Word Prototypes -->
    <div id="multivec" class="page clearfix">
		<div class="container ptb">        
	      	<div class="row">
			<div class="col-md-10  col-md-offset-1">
		    		<div class="build title-page">
						<h2 class="text-center">Word Embeddings Using Multiple Word Prototypes</h2>	
							<div class="line-title bg-primary"></div>
					</div>
			 	</div><!-- end col -->
			</div><!-- end row -->

	        <div class="row">
				<div class="col-md-3">
		          <h5><b>THE PROJECT</b></h5>
		          <p class="desc">This was a project for course CS671A: Introduction to Natural Language Processing, under Prof. Amitabha Mukherjee. Since, existing word vector models do not account for polysemy (reducing the quality), the project aimed at improving word vectors by computing individual word vectors for each sense of a word. The project was completed during Aug '15 - Nov '15.</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-5">
		          <h5><b>PROJECT DESCRIPTION</b></h5>
		          <p class="desc">The project deals with the problem of construction of Multiple Sense Embeddings for different words. We develop several models to tackle the problem consisting of Online Clustering Methods, Methods involving Parameter Estimation and also look at methods related to Word Word Co-occurrence matrices. Our model is comparable to the state of the art models and even outperforms them in some cases. We also discuss the possibility of our model giving better (semantically coherent) senses than present models. The proposal, poster, slides and the final report are avialable (given in the links below). The code repository is hosted at GitHub.</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-4">
		          <h5><b>THE RESULTS</b></h5>
		          <p class="desc">We compare the performance of our approaches with current state of the art models and find that our model is comparable to the state of the art models and even outperforms them in some cases. Our model is extremely efficient and takes less than 6 hours for complete training and computation of senses. The main task used for comparing the models is the SCWS task. The comparisons have been done using human judgment of semantic similarity.</p>
	        	</div><!--/col-md-4-->
	      	</div><!--/row-->


            <div class="row">
            <br><br>
            <center><img src="img/details/cs671_result.jpg" alt="Results" style="width: 65%; height: 65%"></center>
            <br><br><br>
            </div>

	      	<div class="row">
			  	<div class="col-md-4">
		      		<center><a href="resources/multivec_proposal.pdf" class="btn btn-clear btn-lg border-color linear hire">PROPOSAL</a></center>	
				</div><!--/col-md-4-->
	          	<div class="col-md-4">
		      		<center><a href="resources/multivec_poster.pdf" class="btn btn-clear btn-lg border-color linear hire">POSTER</a></center>
				</div><!--/col-md-4-->
	          	<div class="col-md-4">
		      		<center><a href="resources/multivec_report.pdf" class="btn btn-clear btn-lg border-color linear hire">REPORT</a></center>	
				</div><!--/col-md-4-->         
	      	</div><!--/row-->
	      	<br>
	      	<div class="row">
			  	<div class="col-md-4 col-md-offset-2">
		      		<center><a href="resources/multivec_slides.pdf" class="btn btn-clear btn-lg border-color linear hire">PRESENTATION</a></center>	
				</div><!--/col-md-6-->
	          	<div class="col-md-4">
		      		<center><a href="https://github.com/nishantrai18/cs671project" class="btn btn-clear btn-lg border-color linear hire">CODE REPOSITORY</a></center>
				</div><!--/col-md-6-->
	      	</div><!--/row-->

	      	<br>
	    </div>
    </div>

    <!-- Partial Multi View Clustering -->
    <div id="gpmvc" class="page clearfix">
        <div class="container ptb">        
            <div class="row">
            <div class="col-md-12  col-md-offset-0">
                    <div class="build title-page">
                        <h2 class="text-center">Partial Multi-View Clustering Using Graph Regularized NMF</h2>  
                            <div class="line-title bg-primary"></div>
                    </div>
                </div><!-- end col -->
            </div><!-- end row -->

        <div class="container">
           <div class="row panel-default">
            <div class="col-md-10  col-md-offset-1">
              <div class="panel-body">

                  <h4>
                    <strong>Abstract:</strong>
                  </h4>
                  <p class="desc"> Real-world datasets consist of data representations (views) from different sources which often provide information complementary to each other. Multi-view learning algorithms aim at exploiting the complementary information present in different views for clustering and classification tasks. Several multi-view clustering methods that aim at partitioning objects into clusters based on multiple representations of the object have been proposed. Almost all of the proposed methods assume that each example appears in all views or at least there is one view containing all examples. In real-world settings this assumption might be too restrictive. Recent work on Partial View Clustering addresses this limitation by proposing a Non-negative Matrix Factorization based approach called PVC. Our work extends the PVC work in two directions. First, the current PVC algorithm is designed specifically for two-view datasets. We extend this algorithm for the k partial-view scenario. Second, we extend our k partial-view algorithm to include view specific graph laplacian regularization. This enables the proposed algorithm to exploit the intrinsic geometry of the data distribution in each view. The proposed method, which is referred to as GPMVC (Graph Regularized Partial Multi-View Clustering), is compared against 7 baseline methods (including PVC) on 5 publicly available text and image datasets. In all settings the proposed GPMVC method outperforms all baselines. For the purpose of reproducibility, we provide access to our code.
                  </p>
                  <br>

                    <h4>
                        <strong>Results:</strong>
                    </h4>

                    <br>

                    <img src="img/details/nmf_results.jpg" alt="GPMVC Results">
              
                    <br><br>

                    <h4>
                        <strong>Relevant Links:</strong>
                    </h4>

                    <br><br>

                    <!-- External Links -->
                    <div class="row">
                        <div class="col-md-4">
                            <center><a href="resources/gpmvc_presentation.pdf" class="btn btn-clear btn-lg border-color linear hire">PRESENTATION</a></center>   
                        </div>
                        <div class="col-md-4">
                            <center><a href="resources/gpmvcICPR16.pdf" class="btn btn-clear btn-lg border-color linear hire">PAPER</a></center>
                        </div>
                        <div class="col-md-4">
                            <center><a href="https://github.com/nishantrai18/MultiViewNMF" class="btn btn-clear btn-lg border-color linear hire">CODE REPOSITORY</a></center>
                        </div>
                    </div><!--/row-->
                    <br>

              </div>
            </div>
          </div>
        </div>

        </div>
    </div>

    <!-- Computer Networks (Proxy, etc) -->
    <div id="network" class="page clearfix">
        <div class="container ptb">        
            <div class="row">
            <div class="col-md-10  col-md-offset-1">
                    <div class="build title-page">
                        <h2 class="text-center"> Computer Networks Course Project</h2>   
                            <div class="line-title bg-primary"></div>
                    </div>
                </div><!-- end col -->
            </div><!-- end row -->

            <div class="row">
                <div class="col-md-7">
                  <h5><b>THE PROJECT</b></h5>
                  <p class="desc">This was a course project for the course CS425A: Introduction to Computer Networks, under Prof. Sandeep Shukla. The project is an implementation intensive project consisting of multiple mini projects. The mini projects included implementing a basic HTTP server, Proxy server, basic STCP layer and a simple static router. The project was completed during the 7th semester (Aug '16 - Nov '16).</p>
                </div><!--/col-md-4-->
                <div class="col-md-5">
                  <h5><b>PROJECT DESCRIPTION</b></h5>
                  <p class="desc">The project is implementation intensive consisting of multiple mini projects. It involved studying and implementing protocols and network layers. The mini projects included implementing a basic HTTP server, Proxy server, basic STCP layer and a simple static router. The relevant reports and code are provided below.</p>
                </div><!--/col-md-4-->
            </div><!--/row-->

            <br>

            <div class="row">
                <div class="col-md-6">
                    <center><a href="resources/cs425_report.zip" class="btn btn-clear btn-lg border-color linear hire">REPORT</a></center>   
                </div><!--/col-md-4-->
                <div class="col-md-6">
                    <center><a href="resources/cs425_code.zip" class="btn btn-clear btn-lg border-color linear hire">CODE</a></center>
                </div><!--/col-md-4-->
            </div><!--/row-->


        </div>
    </div>

    <!-- ADA Compiler -->
    <div id="ada" class="page clearfix">
        <div class="container ptb">        
            <div class="row">
            <div class="col-md-10  col-md-offset-1">
                    <div class="build title-page">
                        <h2 class="text-center"> ADA Compiler</h2>   
                            <div class="line-title bg-primary"></div>
                    </div>
                </div><!-- end col -->
            </div><!-- end row -->

            <div class="row">
                <div class="col-md-5">
                  <h5><b>THE PROJECT</b></h5>
                  <p class="desc">This was a course Project for the completion of the course CS335A: Compiler Design, under Prof. Subhajit Roy. The project involved creating an End-to-End Compiler for a subset of the programming language ADA in the x86 architecture. The project was completed during the semester (Aug '15 - Nov '15).</p>
                </div><!--/col-md-4-->
                <div class="col-md-7">
                  <h5><b>PROJECT DESCRIPTION</b></h5>
                  <p class="desc">The project involved implementing a Lexical Analyzer and Assembly-Code Generator in python, constructing grammar rules for parsing our identified language and creating the TAC (Three Address Code) for intermediate code. The compiler supported basic types, operations for Strings, Library support, Short circuiting, conditionals, Loops with strict type-checking and error handling. It also supported functions (Allowed overloading) with multiple return values and scopes.</p>
                </div><!--/col-md-4-->
            </div><!--/row-->

            <br>

        </div>
    </div>

    <!-- NachOS Operating System -->
    <div id="nachos" class="page clearfix">
		<div class="container ptb">        
	      	<div class="row">
			<div class="col-md-10  col-md-offset-1">
		    		<div class="build title-page">
						<h2 class="text-center"> NachOS Operating System</h2>	
							<div class="line-title bg-primary"></div>
					</div>
			 	</div><!-- end col -->
			</div><!-- end row -->

	        <div class="row">
				<div class="col-md-6">
		          <h5><b>THE PROJECT</b></h5>
		          <p class="desc">This was a project for course CS330A: Operating Systems, under Prof. Mainak Chaudhuri. The project involved extending the NachOS operating system to perform basic operating system functions including Fork, Join, Sleep and Exec. The project was completed during the semester (Aug '15 - Nov '15).</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-6">
		          <h5><b>PROJECT DESCRIPTION</b></h5>
		          <p class="desc">The project involved extending the NachOS operating system to perform basic operating system functions including Fork, Join, Sleep and Exec. Implemented and evaluated performance of various algorithms for scheduling processes. Developed and added support for Demand Paging, Shared Memory, Condition Variables and Semaphores.</p>
		        </div><!--/col-md-4-->
	      	</div><!--/row-->
	      	<br>
	    </div>
    </div>

    <!-- Adaptive Strategies for Prisoner's Dillema -->
    <div id="ipd" class="page clearfix">
        <div class="container ptb">        
            <div class="row">
            <div class="col-md-12  col-md-offset-0">
                    <div class="build title-page">
                        <h2 class="text-center">Adaptive Strategies for Infinite Prisoner's Dillema</h2> 
                            <div class="line-title bg-primary"></div>
                    </div>
                </div><!-- end col -->
            </div><!-- end row -->

            <div class="row">
                <div class="col-md-4">
                  <h5><b>THE PROJECT</b></h5>
                  <p class="desc">This was a course project in the course ECO502A: Applied Game Theory, under Prof. Vimal Kumar. The project deals with the problem of computing successful strategies for Iterated (Infinite) Prisoner’s dilemma. The discussed algorithms include Evolutionary Strategies and Reinforcement Learning (Which compute optimal and also adaptive strategies which perform well against multiple opponents). We proposed new algorithms based on Reinforcement Learning to compute good strategies which perform well against a set of baseline algorithms.
                  </p>
                </div><!--/col-md-4-->
                <div class="col-md-5">
                  <h5><b>PROJECT DESCRIPTION</b></h5>
                  <p class="desc">The project deals with the problem of computing successful strategies for Iterated (Infinite) Prisoner’s dilemma. We simulate multiple results and also confirm previous findings and claims. We also show the relevance of choosing memory depth as three in Axelrod’s experiments and provide arguments for the same. The discussed algorithms are based on Evolutionary Strategies and Reinforcement Learning. We propose new algorithms based on Reinforcement Learning to compute good strategies performing well against a variety of other strategies. This strategy is also compared against Axelrod’s Evolutionary Strategy.</p>
                </div><!--/col-md-4-->
                <div class="col-md-3">
                  <h5><b>THE RESULTS</b></h5>
                  <p class="desc"> To compute results and analyse the effectiveness of the strategies, we consider Axelrod's Tournament and use a similar setup. We find that our proposed adaptive strategy performs better than other variants. We also discuss the shortcomings and strengths of the algorithms. Other qualitative discussions and results are provided in the report.</p>
                </div><!--/col-md-4-->
            </div><!--/row-->

            <br>

            <div class="row">
                <div class="col-md-4">
                    <center><a href="resources/ipd_report.pdf" class="btn btn-clear btn-lg border-color linear hire">REPORT</a></center>   
                </div><!--/col-md-4-->
                <div class="col-md-4">
                    <center><a href="resources/ipd_extra.pdf" class="btn btn-clear btn-lg border-color linear hire">EXTRA</a></center>
                </div><!--/col-md-4-->
                <div class="col-md-4">
                    <center><a href="https://github.com/nishantrai18/miscProg/tree/master/geneticIPD" class="btn btn-clear btn-lg border-color linear hire">CODE REPOSITORY</a></center>
                </div><!--/col-md-4-->
            </div><!--/row-->

            <br>
        </div>
    </div>

    <!-- Geometric Data Structures -->
    <div id="geodata" class="page clearfix">
		<div class="container ptb">        
	      	<div class="row">
			<div class="col-md-10  col-md-offset-1">
		    		<div class="build title-page">
						<h2 class="text-center">Geometric Data Structures</h2>	
							<div class="line-title bg-primary"></div>
					</div>
			 	</div><!-- end col -->
			</div><!-- end row -->

	        <div class="row">
				<div class="col-md-4">
		          <h5><b>THE PROJECT</b></h5>
		          <p class="desc">This was a project for Advanced Track in course CS210: Data Structures and Algorithms, under Prof. Surendar Baswana. The project involved re-invention of several geometric data structures to efficiently answer specified queries. Some of the involved topics were Convex Hulls, Dynamic hulls, Fractional Cascading, Simplex query. The project was completed during the semester alongside the course (Sep '14 - Nov '14).</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-4">
		          <h5><b>PROJECT DESCRIPTION</b></h5>
		          <p class="desc">The project involved re-invention of several geometric data structures to efficiently answer specified queries. The queries handled were Point in Polygon, Polygon-Line intersection, Simplex problem, Orthogonal Range Search and Half Plane problem. We also re invented solutions for problems such as Improving time complexity of Orthogonal Range Search using Fractional Cascading and Dynamic Convex Hulls. </p>
		        </div><!--/col-md-4-->
		        <div class="col-md-4">
		          <h5><b>QUERIES HANDLED</b></h5>
		          <p class="desc">The operation handled were Computation of Convex Hull, Point in Polygon, Maintaining dynamic Convex hull, Line polygon intersection, Half plane query : Number of points on a given side of a line (Using convex hulls), Fractional Cascading : Improvement in Half Plane Query, Orthognal Range search : Number of points in a rectangle, Half Plane query : Using Ham sandwich cuts, Simplex problem</p>
	        	</div><!--/col-md-4-->
	      	</div><!--/row-->

	      	<br>
	      	<div class="row">
			  	<div class="col-md-6">
		      		<center><a href="resources/geodata_desc.pdf" class="btn btn-clear btn-lg border-color linear hire">DESCRIPTION</a></center>	
				</div><!--/col-md-4-->
	          	<div class="col-md-6">
		      		<center><a href="resources/geodata_report.pdf" class="btn btn-clear btn-lg border-color linear hire">REPORT</a></center>
				</div><!--/col-md-4-->
	      	</div><!--/row-->
	      	<br>
	    </div>
    </div>

    <!-- Multi Modal Emotion Recognition -->
    <div id="emodet" class="page clearfix">
		<div class="container ptb">        
	      	<div class="row">
			<div class="col-md-10  col-md-offset-1">
		    		<div class="build title-page">
						<h2 class="text-center">Multi Modal Emotion Recognition</h2>	
							<div class="line-title bg-primary"></div>
					</div>
			 	</div><!-- end col -->
			</div><!-- end row -->

	        <div class="row">
				<div class="col-md-3">
		          <h5><b>THE PROJECT</b></h5>
		          <p class="desc">This was a project in the Summer Camp organized by SnT Council in '14. It was completed in the summers under the Programming Club. The project aims at performing emotion recognition using multiple features i.e. text, visual and acoustic features. We then use ensemble methods on the classifiers formed to get improved results (To consider multiple aspects).</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-4">
		          <h5><b>PROJECT DESCRIPTION</b></h5>
		          <p class="desc">This project presents a multimodal emotion recognition model which aims at acheiving higher accuracies than the present ones using all the prevalent features in a video, namely text, audio, video. We are classifying the videos into neutral and the 6 basic Ekman emotions [1]. We have decided to use three independent classifiers, one each for text, audio and video. The text classifier gives positive-negative scores showing the extent to which a given statement is positive or negative.</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-5">
		          <h5><b>THE RESULTS</b></h5>
		          <p class="desc">I'll briefly describe the recognition rates of the different classifiers. Our model consisted of three independent classifiers which were merged later. For the text classifier, the accuracy was roughly 74% for all of them, with the Naive Bayes model performing slightly better. The Image classifier used many different approaches. The best accuracy achieved was around 65%. The audio classifier uses Mel frequency cepstrum coefficients as features after a bit of pre and post processing. Support Vector Machines and K Nearest Neigbors are used, the best accuracy acheived was 60%. The result improves when the results of all three are considered together.</p>
	        	</div><!--/col-md-4-->
	      	</div><!--/row-->

	      	<br><br>

	      	<div class="row">
			  	<div class="col-md-3">
		      		<center><a href="resources/emodet_wiki.html" class="btn btn-clear btn-lg border-color linear hire">PROJECT WIKI</a></center>	
				</div><!--/col-md-4-->
	          	<div class="col-md-3">
		      		<center><a href="resources/emodet_report.pdf" class="btn btn-clear btn-lg border-color linear hire">REPORT</a></center>	
				</div><!--/col-md-4-->         
			  	<div class="col-md-3">
		      		<center><a href="https://www.youtube.com/watch?v=epqfspbhRp0" class="btn btn-clear btn-lg border-color linear hire">DEMONSTRATION</a></center>	
				</div><!--/col-md-6-->
	          	<div class="col-md-3">
		      		<center><a href="https://github.com/nishantrai18/affective_computing" class="btn btn-clear btn-lg border-color linear hire">CODE REPOSITORY</a></center>
				</div><!--/col-md-6-->
	      	</div><!--/row-->
	    	<br>
	    </div>
    </div>

    <!-- News Report Classification -->
    <div id="newsrep" class="page clearfix">
		<div class="container ptb">        
	      	<div class="row">
			<div class="col-md-10  col-md-offset-1">
		    		<div class="build title-page">
						<h2 class="text-center">News Report Classification</h2>	
							<div class="line-title bg-primary"></div>
					</div>
			 	</div><!-- end col -->
			</div><!-- end row -->

	        <div class="row">
				<div class="col-md-6">
		          <h5><b>THE PROJECT</b></h5>
		          <p class="desc">This was a project taken in the Second semester (Of First Year) under ACA (Association of Computing Activities). This was my first project related to Machine Learning, and introduced me to the wonderful world of ML. The project aims at classifying new reports into multiple categories. We use basic concepts related to Natural Langauge Proccesing and try a few models to compare their performance.</p>
		        </div><!--/col-md-4-->
		        <div class="col-md-6">
		          <h5><b>PROJECT DESCRIPTION</b></h5>
		          <p class="desc">The project aims at classifying news articles into various categories. We trained a Naive Bayes Classifier after processing the article text (Tokenisation, Stemming, removing Stopwords, etc) on scraped news data. We implemented K Nearest Neighbors and automated scraping of online news articles for collection of Training data. We also used NLTK (Library) and The Reuters News dataset as validation sets.</p>
		        </div><!--/col-md-4-->
	      	</div><!--/row-->
	      	<br>
	    </div>
    </div>

    <!-- Other Projects -->
    <div id="other" class="page clearfix">
        <div class="container ptb">        
            <div class="row">
            <div class="col-md-12  col-md-offset-0">
                    <div class="build title-page">
                        <h2 class="text-center">Other Minor Projects</h2>  
                            <div class="line-title bg-primary"></div>
                    </div>
                </div><!-- end col -->
            </div><!-- end row -->

        <div class="container">
           <div class="row panel-default">
            <div class="col-md-10  col-md-offset-1">
              <div class="panel-body">


<!-------------------------------------------------------------------------------------------------------------------------------->
                <h4>
                    <strong><a href="https://github.com/VaidehiSom/GestureRecognition">Gesture Recognition controlled Robotic Arm</a></strong> | Deep Learning, Computer Vision, ROS
                </h4>
                <!-- <h6>
                  <div class="right"> <small> May ’20 - Jul ’20 </small></div>
                  </h6>
                <br> -->
                <div class="about-content">  
                      <UL>
                        <LI>Implemented ResNet, non-max suppression, huber loss, and detected hand landmarks Video/Report
                            <LI>Generated data of 25k images, performed data augmentation to obtain 98% accuracy with loss less than 1
                        <LI>Detected key-points from video input using Intel-RealSense Camera, were used to define various gestures
                        <LI>Simulated robotic arm using ROS and Gazebo to perform pick up tasks. Enhanced arm movements using gesture inputs
                      </UL>
                  </div>
                  <br>
    
                  <h4>
                    <strong><a href="https://github.com/VaidehiSom/StereoVO">Stereo Visual Odometry</a></strong> | Geometric Computer Vision, C++, Ceres, Kitti
                </h4>
                <!-- <h6>
                  <div class="right"> <small> May ’20 - Jul ’20 </small></div>
                  </h6>
                <br> -->
                <div class="about-content">  
                      <UL>
                        <LI> Implemented Stereo Visual Odometry for stereo images to find 3D locations of keypoints in those images
                        <LI> Used GFTT for feature detection and triangulation for 3D point location
                        <LI> Implemented direct method and optical flow for pose and feature estimation during feature tracking
                        <LI> Implemented Bundle Adjustment for backend optimization
                      </UL>
                  </div>
                  <br>
    
    
                <h4>
                  <strong><a href="https://github.com/VaidehiSom/Trajectory_Prediction_and_Dynamic_Obtacle_Avoidance_for_SDC">Trajectory prediction and Dynamic Obstacle avoidance for SDC</a></strong> | PINN, LSTM, Deep Learning
              </h4>
              <div class="about-content">  
                    <UL>
                      <LI> Implemented and compared Social LSTM, OLSTM and GRU for pedestrians trajectory prediction
                      <LI> Modelled the non linear dynamics of MPC using Physics informed Neural Nets for motion planning
                      <LI> Used Lifelong A* and pedestrian’s trajectory as dynamic obstacles for planning obstacles
                        </UL>
                </div>
                <br>
                
                
                
    
                  <h4>
                    <strong><a href="https://github.com/VaidehiSom/MobileRobot_Simulation_and_SLAM">Mobile Robot: Simulation and SLAM</a></strong> | ROS Navigation stack, C++, AMCL, EKF, Gazebo
                  </h4>
                  <div class="about-content">
                      <UL>
                        <LI> Simulated ball chasing robot, detection via colors. Designed URDF model and arena
                          <LI>  Implemented localization using AMCL, gmapping for 2D and RTABMap for 3D mapping
                            <LI> Deployed SLAM and Navigation using Dijkstra algorithm and simulated pick and place operation
                      </UL>
                  </div>


<!----------------------------------------------------------------------->
            <h4>
                <strong><a href="https://github.com/VaidehiSom/RoboticArm">Robotic Arm 6 dof</a></strong>
              </h4>
              <div class="about-content">
                  <UL>
                    <LI> Developed and programmed 6 dof Robotic arm for 2 kgs payload
                    <LI>  Implemented forward and inverse kinematics executed by micro controllers for position control of DC motors
                    <LI>  Programmed motion planning. Modifiable to perform pick/place using different end effectors
                  </UL>
              </div>
              <br>

            <h4>
              <strong><a href="https://github.com/VaidehiSom/CombatRobot">Combat Robot</a></strong>
            </h4>
            <div class="about-content">
                <UL>
                  <LI> Self-designed and fabricated the combat bot which in turn is capable of destroying other bots using its weapon mechanism consisting of a rotating drum
                    <LI> Led the team of 6 members for participating in Robowars event at IIT Bombay’s TechFest
                      <LI> One of the 20 teams selected from all over India for the main event at IIT Bombay
                        <LI> The bot was manufactured to battle with other bots in 15kgs category
                </UL>
            </div>
            <br>

            <h4>
              <strong><a href="https://github.com/VaidehiSom/Quadruped">Quadruped</a></strong> | Python, ROS 
            </h4>
            <div class="about-content">
                <UL>
                  <LI> Fabrication of Quadruped, inspired by MIT spot micro
                    <LI>  Communication of motors and motor drivers
                      <LI>  Integrated IMU data, via arduino, for improved odometry and balance
                        <LI>  Using ROS Navigation stack
                </UL>
            </div>
            <br>

              <h4>
                <div class="left"> <strong><a href="https://github.com/VaidehiSom/WindowCleaningRobot">Window Cleaning Robot - Design</a></strong> </div>
                <!-- <div class="left"> <strong>Window Cleaning Robot - Design</strong> </div> -->
                    <!-- <div class="right"> <strong> Jan '20</strong> </div> -->
                    <br>
              </h4>
              <div class="about-content">
                  <UL>
                    <LI> Designed a novel model for window cleaning robot in Tech Fest, IIT Ropar using Solidworks. 3rd position out of 15 teams
                    <LI> Used concepts of Electric Ducted fans(EDF), speed controller, IR/IMU sensors, Drivers, and Arduino Mega for designing
                  </UL>
              </div>
              <br>

              <h4>
                    <div class="left"> <strong><a href="https://github.com/VaidehiSom/RouteOptimization">BOSCH-Bus Route Optimization</a></strong> </div>
                    <!-- <div class="right"> <strong> Dec '19</strong> </div> -->
                    <br>
              </h4>
              <div class="about-content">
                  <UL>
                    <LI>  Constraint programming, OR tools, Google MAP API
                      <LI>  Inter IIT Tech Fest, earned silver medal
                  </UL>
              </div>
              <br>

              <h4>
                    <div class="left"> <strong><a href="">Multi View Geometry</a></strong> </div>
                    <!-- <div class="right"> <strong> May '16 - Jul '16</strong> </div> -->
                    <br>
              </h4>
              <div class="about-content">
                  <UL>
                     <LI> Compute camera pose and 3D point cloud from images using Structure from Motion, Bundle adjustment
                      <LI>  Camera localization using PnP, point triangulation, non linear refinement
                  </UL>
              </div>
              <br>

              <h4>
                <strong><a href="https://github.com/VaidehiSom?tab=repositories">Environment perception for self driving car</a></strong> | Python, RANSAC, Segmentation
              </h4>
              <div class="about-content">
                  <UL>
                    <LI> Implemented drivable space estimation in 3D, lane estimation, and obstacle distance from car using the output of semantic segmentation neural networks
                  </UL>
              </div>
              <br>

              <h4>
                    <strong><a href="">Other Minor Projects</a></strong>
              </h4>
              <div class="about-content">
                  <UL>
                    <LI>  Implement ES-EKF to localize self driving car in simulation</LI>
                    <LI> Style Transfer </LI>

                   </UL>
              </div>
              <br>
              
<!-------------------------------------------------------------------------------------------------------------------------------------->

                    <div class="about-content">
                          <UL>
                            <LI> Developed a bot to play <strong>Othello</strong>. It was based on the Minimax algorithm. Alpha-beta Pruning is also performed to speed up computations. Secured <strong>19th</strong> place amongst <strong>2000+</strong> participants from over the world.
                            <LI> Designed a bot to play <strong>Battleship</strong>. A probabilistic model of the ships and board was used to decide the next move.
                            <LI> Designed application for <strong>Analysing brand sentiment</strong> through social media channels. Developed during Web-Dev, Takneek '14 and secured <strong>First</strong> position.
                            <LI> Developed models for predicting <strong>Search trends</strong> and detecting <strong>Spam</strong> messages.
                            <LI> Implemented models for <strong>Topic assignment</strong> for articles, <strong>Multi-Label Question classification</strong> (Tested on questions taken from Quora).
                            <LI> Developed a <strong>Captcha Decoder</strong>, able to work with mild occlusions. Clustering and Segmentation based methods used for extracting candidate regions containing characters. They are further passed through a classifier to get the final results.
                            <LI> Completed project to discover patterns and trends about the New York Subway, during the Udacity course: <strong>Intro to Data Science</strong>.
                          </UL>
                    </div>

                    <br>

                    <!-- External Links -->
                    <div class="row">
                        <div class="col-md-12">
                            <center><a href="https://github.com/nishantrai18/miscProg" class="btn btn-clear btn-lg border-color linear hire">CODE REPOSITORY</a></center>
                        </div>
                    </div><!--/row-->
                    <br>

              </div>
            </div>
          </div>
        </div>

        </div>
    </div>


    <!--contact-->
    <div id="contact" class="page page-bgcolor">
		<div class="container">
		<div class="row">
          <div class="col-md-10  col-md-offset-1">
		    <div class="build title-page">
		      		<center><a href="index.html" class="btn btn-clear btn-lg border-color linear hire">BACK TO HOMEPAGE</a></center>		
			</div>
		   </div><!-- end col -->
		</div><!-- end row -->
	  </div><!-- end container -->
	</div>
    <!--contact-->
    
    <!-- Footer -->
    <footer class="bg-black">
      <div class="container">
        <div class="row">
            <div class="col-md-7 text-right">
        
            <ul class="list-inline">
            <li><a href="https://github.com/VaidehiSom" class="socIcon color-primary linear"><i class="fa fa-github fa-2x"></i></a></li>
            <li><a href="https://www.linkedin.com/in/vaidehi-som-5aa020165/" class="socIcon color-primary linear"><i class="fa fa-linkedin fa-2x"></i></a></li>
            <li><a href="https://twitter.com/SomVaidehi" class="socIcon color-primary linear"><i class="fa fa-twitter fa-2x"></i></a></li>
            <li><a href="https://vaidehi-som.medium.com/" class="socIcon color-primary linear"><i class="fa fa-medium fa-2x"></i></a></li>
            <li><a href="https://www.instagram.com/vaidehisom/" class="socIcon color-primary linear"><i class="fa fa-instagram fa-2x"></i></a></li>
            </ul>
        
            </div>
        </div>
      </div>
    </footer>
    <!-- /Footer -->

    <!-- JavaScript -->
    <script src="js/jquery-1.10.2.js"></script>
    <script src="js/bootstrap.js"></script>
	<script src="js/jquery.sticky.js" ></script>
	 <script src="js/jquery.nav.js"></script>
    <script src="js/jquery.scrollTo.js" ></script>
    <script src="js/jquery.flexslider.js" ></script>
   <script type="text/javascript" src="js/ekko-lightbox.js"></script>
   <script src="js/jquery.easing.1.3.js" ></script>
   <script src="js/jquery.shuffle.js" ></script>
    <script src="js/script.js"></script>

    <!-- Custom JavaScript for the Side Menu and Smooth Scrolling -->
    
    <!-- <script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-72535905-1', 'auto');
	  ga('send', 'pageview');
	</script> -->

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-VVWJ7K9WFV"></script>
  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VVWJ7K9WFV');
  </script>

  </div>
  </body>

</html>